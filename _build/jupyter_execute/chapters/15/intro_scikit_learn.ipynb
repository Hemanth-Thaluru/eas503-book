{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b23f4462",
   "metadata": {},
   "source": [
    "# Introduction to Scikit-learn \n",
    "  - Choose the right estimator -- the right algorithm for doing ML\n",
    "    - https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
    "  - Consistent -- all object share a common interface\n",
    "  - Inspection -- all parameter values are exposed as public attributes\n",
    "  - Limited object Hierarchy -- algorithms are represented as Python classes, datasets mainly as numpy array and parameters as standard python strings \n",
    "  - Composition -- ML as a sequences of fundamental algorithms\n",
    "  - Defaults -- provides good default values\n",
    "\n",
    "## High Level Steps\n",
    "  - Choose the class of model to be coded\n",
    "  - Choose the hyper parameters of the model\n",
    "  - Arrange data into target and features\n",
    "  - Write model fitment code using fit() method. \n",
    "\n",
    "## General Steps\n",
    "  - Load Data\n",
    "    - Three ways load data\n",
    "      - Dataset loaders (toy datasets that come with skikit-learn)\n",
    "        - Good for illustrating how the various algorithms work\n",
    "      - Dataset fetchers (real world datasets)\n",
    "        - Built-in functions to load large datasets\n",
    "        - Pull from openml.org\n",
    "      - Dataset generation functions\n",
    "        - Artificial datasets -- can create labeled datasets\n",
    "        - \n",
    "  - Pre-process Data\n",
    "    - Remove mean **\n",
    "    - Scale Variance **\n",
    "    - Non-linear transformation\n",
    "    - Normalization\n",
    "    - Encoding categorical features\n",
    "    - Discretization\n",
    "    - Imputation of missing values \n",
    "    - Maybe remove outliers if it can be justified. Always document this in research paper\n",
    "\n",
    "## Loading data\n",
    "\n",
    "## Preprocessing\n",
    "\n",
    "### Mean and Variance\n",
    "- algorithms require that all the features have variance of similar magnitude. If the magnitude differ by orders of magnitude larger than others, it might dominate the objective function.\n",
    "  - Whatever mean or std you subtract from the training set, you have to use the same on the testing set. \n",
    "- Algorithms assume that the input data is Gaussian distribution with zero mean and unit variance. \n",
    "- Power transformers aim to map data from any distribution to as close to a Gaussian distribution \n",
    "\n",
    "### Encoding\n",
    "- Map text values to integer codes. For example, instead of using text for city names, use integers, or Male = 0, Female = 1. This allows fitting numerical values into models. \n",
    "\n",
    "### Discretization \n",
    "- Turn continuous values in to discrete values. You bin the continuous into bins. *** Linear models can become non-linear due to discretization \n",
    "\n",
    "\n",
    "### Imputation \n",
    "- Many real world datasets contain missing values; \n",
    "  - Discard entire rows\n",
    "  - Or fill data -- usually by guessing from available data\n",
    "\n",
    "\n",
    "## Splitting Data\n",
    "- It is common to split data into training and testing samples. \n",
    "- Usually you do 90/10 or 80/20. \n",
    "- The splitting has to be random\n",
    "- K-Cross-fold validation -- split data K times\n",
    "\n",
    "## Linear Regression\n",
    "- LR models the relationship between a dependent variable and one or more independent variable. When one increase or decrease, the other increases or decreases. \n",
    "\n",
    "## Naive Bayes\n",
    "- Simple supervised machine learning classifier\n",
    "- Assumes the features are independent \n",
    "  - Example -- apple is red, round and 4 cm in diameter \n",
    "\n",
    "## Support Vector Machine (SVM)\n",
    "- Another supervised machine learning classifier\n",
    "  - use for both classification and regression \n",
    "- Can do non-linear classification\n",
    "- Hyper plane -- maximize the margin between two classes\n",
    "- Support Vectors -- data points that define the hyper plane \n",
    "- Margin width -- define an optimal hyper plane we need to maximize the width\n",
    "of the margin \n",
    "\n",
    "\n",
    "## Evaluation \n",
    "Ref: https://en.wikipedia.org/wiki/Receiver_operating_characteristic\n",
    "Ref: https://datascience-enthusiast.com/Python/ROC_Precision-Recall.html\n",
    "\n",
    "![roc](Roc_curve.svg.png)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "source_map": [
   11
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}